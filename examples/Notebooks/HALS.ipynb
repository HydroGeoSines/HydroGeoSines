{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f03bb1ca",
   "metadata": {},
   "source": [
    "# HydroGeoSines\n",
    "## HALS\n",
    "Short tutorial on how to apply the HALS method to both regularly and irregularly sampled data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42867d3",
   "metadata": {},
   "source": [
    "### Import HGS\n",
    "Currently, the HydroGeoSines is not fully implemented as an installable package. Instead. we have to move to the parent directory, to import the package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5013f31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory  /media/daniel/SharedData/Workspaces/GitHub/HydroGeoSines\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"../../\")\n",
    "print(\"Current Working Directory \" , os.getcwd())\n",
    "\n",
    "# Load the HGS package\n",
    "import hydrogeosines as hgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f045a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and other packages used in this tutorial\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "939eabeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<hydrogeosines.models.site.Site object at 0x7fb64c7878b0>\n"
     ]
    }
   ],
   "source": [
    "# Create a Site object\n",
    "example_site = hgs.Site('example', geoloc=[141.762065, -31.065781, 160])\n",
    "print(example_site)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0dfb90",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "### The groundwater head records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71d5cfc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A new time series was added ...\n",
      "No duplicate entries were found.\n"
     ]
    }
   ],
   "source": [
    "# Load all our data attributed to the Site\n",
    "example_site.import_csv('tests/data/notebook/GW_record.csv', \n",
    "                        input_category=[\"GW\"]*3, \n",
    "                        utc_offset=10, \n",
    "                        unit=[\"m\"]*3,\n",
    "                        loc_names = [\"Loc_A\",\"Loc_B\"], \n",
    "                        header = None,\n",
    "                        check_duplicates=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287bbd22",
   "metadata": {},
   "source": [
    "### The barometric pressure records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29d5515d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A new time series was added ...\n",
      "No duplicate entries were found.\n"
     ]
    }
   ],
   "source": [
    "example_site.import_csv('tests/data/notebook/BP_record.csv', \n",
    "                        input_category=\"BP\", \n",
    "                        utc_offset=10, \n",
    "                        unit=\"m\", \n",
    "                        loc_names = \"Baro\",\n",
    "                        header = None,\n",
    "                        how=\"add\", check_duplicates=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e23c73",
   "metadata": {},
   "source": [
    "### HALS\n",
    "#### With regularly sampled data\n",
    "First we need to regularly sample our groundwater data and align it with te BP records. The RegularAndAlign method does just that. However, the original data in the processing object is not yet updated, as the regular data has its own attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca392715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.73 % of the 'GW' data at 'Loc_A_all' was interpolated due to gaps < 5000s!\n",
      "5.08 % of the 'GW' data at 'Loc_B_all' was interpolated due to gaps < 5000s!\n",
      "Data of the category 'GW' is regularly sampled now!\n",
      "\n",
      "Start iteration No. 1 ...\n",
      "\n",
      "----- Loc_A_1 -----\n",
      "BP record resampled to 1 sample per 300s.\n",
      "\n",
      "Processing BP gaps ...\n",
      "0.02 % of the 'BP' data at 'Baro_all' was interpolated due to gaps < 5000s!\n",
      "... record gaps between 2001-02-27 16:30 and 2001-03-01 07:15 too large for interpolation!\n",
      "\n",
      "Processing GW gaps ...\n",
      "... dropping GW and BP entries for which BP record gaps are too big.\n",
      "0.00 % of the 'GW' data at 'Loc_A_1' was interpolated due to gaps < 5000s!\n",
      "\n",
      "----- Loc_B_1 -----\n",
      "BP record resampled to 1 sample per 300s.\n",
      "\n",
      "Processing BP gaps ...\n",
      "6.10 % of the 'BP' data at 'Baro_all' was interpolated due to gaps < 5000s!\n",
      "... record gaps between 2001-02-27 16:30 and 2001-03-01 07:15 too large for interpolation!\n",
      "\n",
      "Processing GW gaps ...\n",
      "... dropping GW and BP entries for which BP record gaps are too big.\n",
      "0.00 % of the 'GW' data at 'Loc_B_1' was interpolated due to gaps < 5000s!\n",
      "The groundwater (GW) and  BP data is aligned. There is exactly one BP for every GW entry!\n"
     ]
    }
   ],
   "source": [
    "process_HALS_rs = hgs.Processing(example_site).RegularAndAligned(inter_max=5000, part_min=20,inter_max_total=40)\n",
    "process_HALS_rs.site.data = process_HALS_rs.data_regular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a379814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Method: hals\n",
      "-------------------------------------------------\n",
      "> Calculating HALS for location: Loc_B\n",
      "Data category: GW\n",
      ">> Condition number: 102\n",
      ">> Error variance: 0.000031\n",
      ">> DC component: 0.000007\n",
      "Data category: BP\n",
      ">> Condition number: 89\n",
      ">> Error variance: 0.000035\n",
      ">> DC component: 0.000097\n",
      "-------------------------------------------------\n",
      "> Calculating HALS for location: Loc_B\n",
      "Data category: GW\n",
      ">> Condition number: 510\n",
      ">> Error variance: 0.000014\n",
      ">> DC component: 0.000018\n",
      "Data category: BP\n",
      ">> Condition number: 226\n",
      ">> Error variance: 0.000157\n",
      ">> DC component: -0.000030\n"
     ]
    }
   ],
   "source": [
    "results_HALS_rs = process_HALS_rs.hals(\"Loc_B\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06aad2c",
   "metadata": {},
   "source": [
    "#### With irregularly sampled data and BP records that are not aligned with the GW data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63e8d197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Method: hals\n",
      "-------------------------------------------------\n",
      "> Calculating HALS for location: Loc_B\n",
      "Data category: BP\n",
      ">> Condition number: 33\n",
      ">> Error variance: 0.000230\n",
      ">> DC component: -0.000031\n",
      "Data category: GW\n",
      ">> Condition number: 23\n",
      ">> Error variance: 0.000025\n",
      ">> DC component: -0.000008\n"
     ]
    }
   ],
   "source": [
    "# Running HALS with irregularly sampled data\n",
    "results_HALS_irs = hgs.Processing(example_site).hals(loc=\"Loc_B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b098b07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The error variance of the irregularly sampled and non-aligned BP records at Loc_B 1 and 2 is 5.65% and 0.47% higher, respectively, compared to the regularly sampled data.\n",
      "\n",
      "The error variance of the irregularly sampled GW records at Loc_B 1 and 2 is -0.20% and 0.76% higher, respectively, compared to the regularly sampled data.\n"
     ]
    }
   ],
   "source": [
    "# irregular sampling results\n",
    "BP_irs = results_HALS_irs[\"hals\"][(\"Loc_B\",\"all\",\"BP\")][0][\"error_var\"]\n",
    "GW_irs = results_HALS_irs[\"hals\"][(\"Loc_B\",\"all\",\"GW\")][0][\"error_var\"]\n",
    "\n",
    "# regular sampling results\n",
    "BP_1_rs = results_HALS_rs[\"hals\"][(\"Loc_B\",\"1\",\"BP\")][0][\"error_var\"]\n",
    "GW_1_rs = results_HALS_rs[\"hals\"][(\"Loc_B\",\"1\",\"GW\")][0][\"error_var\"]\n",
    "\n",
    "BP_2_rs = results_HALS_rs[\"hals\"][(\"Loc_B\",\"2\",\"BP\")][0][\"error_var\"]\n",
    "GW_2_rs = results_HALS_rs[\"hals\"][(\"Loc_B\",\"2\",\"GW\")][0][\"error_var\"]\n",
    "\n",
    "print(\"\\nThe error variance of the irregularly sampled and non-aligned BP records at Loc_B 1 and 2 is {:.2f}% and {:.2f}% higher, respectively, compared to the regularly sampled data.\".format((BP_irs-BP_1_rs)/BP_1_rs,(BP_irs-BP_2_rs)/BP_2_rs))\n",
    "\n",
    "print(\"\\nThe error variance of the irregularly sampled GW records at Loc_B 1 and 2 is {:.2f}% and {:.2f}% higher, respectively, compared to the regularly sampled data.\".format((GW_irs-GW_1_rs)/GW_1_rs,(GW_irs-GW_2_rs)/GW_2_rs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
